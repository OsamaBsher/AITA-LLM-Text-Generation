{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/osama/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex patterns\n",
    "\n",
    "yta_regex = r'\\byta\\b'\n",
    "yta_pattern = re.compile(yta_regex, flags=0)\n",
    "\n",
    "esh_regex = r'\\besh\\b'\n",
    "esh_pattern = re.compile(esh_regex, flags=0)\n",
    "\n",
    "nta_regex = r'\\bnta\\b'\n",
    "nta_pattern = re.compile(nta_regex, flags=0)\n",
    "\n",
    "nah_regex = r'\\bnah\\b'\n",
    "nah_pattern = re.compile(nah_regex, flags=0)  \n",
    "\n",
    "remove_edit_regex = r'edit:.*|update:.*'\n",
    "remove_edit_pattern = re.compile(remove_edit_regex, flags=0)\n",
    "\n",
    "newline_regex = r'(\\r\\n)+|\\r+|\\n+|\\t+'\n",
    "newline_pattern = re.compile(newline_regex, flags=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def removeTextEdit(text): \n",
    "    return remove_edit_pattern.sub(\"\", text)\n",
    "\n",
    "def removeNewlineChars(text):\n",
    "    return newline_pattern.sub(\" \", text)\n",
    "\n",
    "def getCommentVerdict(comment):\n",
    "\n",
    "    comment = newline_pattern.sub(\" \", comment)\n",
    "\n",
    "    if yta_pattern.search(comment):\n",
    "        return \"yta\"\n",
    "    elif nta_pattern.search(comment):\n",
    "        return \"nta\"\n",
    "    elif esh_pattern.search(comment):\n",
    "        return \"esh\"\n",
    "    elif nah_pattern.search(comment):\n",
    "        return \"nah\"\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "329349it [08:39, 633.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read file\n",
    "df = pd.read_csv('/Users/osama/Documents/finalNlu/data/dataPreProcessing/pre_processed_dataset.csv')\n",
    "\n",
    "# Prepare write file\n",
    "file = open('cleaned_dataset.csv',\"w\",encoding=\"utf-8\", newline=\"\") \n",
    "writer = csv.writer(file, quoting=csv.QUOTE_ALL)\n",
    "writer.writerow([\"id\", \"title\", \"text\", \"verdict\", \"comment1\",  \"comment2\", \"score\"])\n",
    "\n",
    "# Iterate over file\n",
    "counter = 0\n",
    "yta_count = 0\n",
    "nta_count = 0\n",
    "\n",
    "text_sizes = []\n",
    "comment1_sizes = []\n",
    "comment2_sizes = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "\n",
    "    id = row['id']\n",
    "    title = row['title'].lower()\n",
    "    text = row['text'].lower()\n",
    "    edited = row['edited']\n",
    "    verdict = row['verdict']\n",
    "    comment1 = row['comment1'].lower()\n",
    "    comment2 = row['comment2'].lower()\n",
    "    comment3 = str(row['comment3']).lower()\n",
    "    comment4 = str(row['comment4']).lower()\n",
    "    comment5 = str(row['comment5']).lower()\n",
    "    comment6 = str(row['comment6']).lower()\n",
    "    comment7 = str(row['comment7']).lower()\n",
    "    comment8 = str(row['comment8']).lower()\n",
    "    comment9 = str(row['comment9']).lower()\n",
    "    comment10 = str(row['comment10']).lower()\n",
    "    score = row['score']\n",
    "    url = row['url']\n",
    "    time_created = row[\"time_created\"]\n",
    "    \n",
    "    # If not edited the value is \"False\" else it is a timestamp\n",
    "    if edited != \"False\":\n",
    "        text = removeTextEdit(text)\n",
    "\n",
    "    comment1 = removeTextEdit(comment1)\n",
    "    comment2 = removeTextEdit(comment2)\n",
    "\n",
    "    # Remove newline characters\n",
    "    title = removeNewlineChars(title)\n",
    "    text = removeNewlineChars(text)\n",
    "    comment1 = removeNewlineChars(comment1)\n",
    "    comment2 = removeNewlineChars(comment2)\n",
    "\n",
    "    # Update verdict based on comment verdict\n",
    "    verdict1 = getCommentVerdict(comment1)\n",
    "    verdict2 = getCommentVerdict(comment2)\n",
    "\n",
    "    # Make sure verdict of top 2 comments are equal\n",
    "    if verdict1 == None or verdict2 == None or verdict2 != verdict1:\n",
    "        continue\n",
    "\n",
    "    # Update verdict with verdict of top 2 comments\n",
    "    verdict = verdict1\n",
    "\n",
    "\n",
    "    # Check length and filter by length\n",
    "    text_size = len(word_tokenize(text))\n",
    "    comment1_size = len(word_tokenize(comment1))\n",
    "    comment2_size = len(word_tokenize(comment2))\n",
    "\n",
    "    # Minimum number of tokens for a comment and post\n",
    "    min_comment_tokens = 5\n",
    "    min_post_tokens = 10\n",
    "\n",
    "    # Skip posts with comments shorter than min_comment_tokens\n",
    "    if comment1_size < min_comment_tokens or  comment2_size < min_comment_tokens:\n",
    "        continue\n",
    "\n",
    "    # Skip posts with length shorter than min_comment_tokens\n",
    "    if text_size < min_post_tokens:\n",
    "        continue\n",
    "\n",
    "    row = [id, title, text, verdict, comment1, comment2, score]\n",
    "\n",
    "    writer.writerow(row)\n",
    "\n",
    "file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
